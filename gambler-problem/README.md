# **Reinforcement Learning: Gamblerâ€™s Problem**

This project implements solutions to the **Gamblerâ€™s Problem**, based on **Chapter 4: Dynamic Programming** from the book **Reinforcement Learning: An Introduction** by **Richard S. Sutton & Andrew G. Barto**.


---

## **ğŸ“‚ Project Structure**
```
gambler-problem/
â”‚â”€â”€ src/                       # Core implementation
â”‚   â”œâ”€â”€ __init__.py            
â”‚   â”œâ”€â”€ gambler.py             # Gambler's problem DP logic
â”‚â”€â”€ notebooks/                 # Jupyter Notebooks for experimentation
â”‚   â”œâ”€â”€ gambler_problem.ipynb  
â”‚â”€â”€ book_images/               # Reference images from the book
â”‚   â”œâ”€â”€ Figure_4_3.PNG         # Figure from Sutton's book
â”‚â”€â”€ generated_images/          # Plots generated from simulations
â”‚   â”œâ”€â”€ figure_4_3.png         # Generated plot from gambler problem
â”‚â”€â”€ README.md                  # Project documentation
```


---

## ğŸ“Œ Key Features  
âœ… Implements **Dynamic Programming** for solving the **Gamblerâ€™s Problem**.  
âœ… Visualizes the **value function** and **policy iteration process**.  
âœ… Simulates different **betting strategies** and their outcomes.  
âœ… Clean separation between **logic and experiments** using notebooks.  
âœ… Great for building foundational understanding of **RL and DP**.

---

## ğŸ“Š Results and Visualizations

### 1ï¸âƒ£ Figure 4.3 from Sutton's Book  
This figure demonstrates the policy iteration results for the Gamblerâ€™s Problem, as shown in Suttonâ€™s book.

ğŸ“ˆ **Visualization:**

<img src="book_images/Figure_4_3.PNG" alt="Figure 4.3" width="400"/>

_This image is taken directly from the book to illustrate the gamblerâ€™s problem setup._

---

### 2ï¸âƒ£ Generated Simulation Results  
These are visualizations of simulation results for different strategies applied to the gamblerâ€™s problem.

ğŸ“ˆ **Visualization:**

<img src="generated_images/figure_4_3.png" alt="Figure 4.3" width="400"/>

_This plot shows the results generated from the gamblerâ€™s problem using dynamic programming._

---

## ğŸ“¢ Conclusion

This project explores **Dynamic Programming techniques** applied to the **Gamblerâ€™s Problem**:

- **Policy iteration** for optimizing the gamblerâ€™s strategy.  
- Exploration of **betting strategies** using DP methods.  
- A step toward understanding **model-based reinforcement learning**.

Through these techniques, we gain insights into **decision-making under uncertainty** and **optimal policies** for simple games.

---
